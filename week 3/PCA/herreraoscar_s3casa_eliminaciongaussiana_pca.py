# -*- coding: utf-8 -*-
"""HerreraOscar_S3CASA_EliminacionGaussiana_PCA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15jscjxol257YeZZwbPzK662pPhjBr-wn

ELIMINACIÓN GAUSSIANA
"""

#Escriba un código de eliminación Gaussiana para resolver el sistema Ax=B.

import numpy as np
N=np.random.randint(3, 7)
A=(np.random.random((N,N))*10.0)-5.0
B=(np.random.random((N,1))*10.0)-5.0

print(N)

N_A=np.concatenate((A,B),axis=1)

for i in range(N):
  N_A[i,:]=N_A[i,:]/N_A[i,i]
  for j in range(i+1,N):
      N_A[j,:]=N_A[j,:]-(N_A[i,:]*N_A[j,i])

for i in range(N-1,0,-1):
  for j in range(i-1,-1,-1):
    N_A[j,-1]=N_A[j,-1]-N_A[j,i]*N_A[i,-1]
SOlUCION=N_A[:,-1]

SOlUCION_NP=np.linalg.solve(A,B)

Error=np.abs(SOlUCION-SOlUCION_NP[:,0])
E_C_M=np.sqrt(np.power(np.sum(Error),2)/N)#error cuadratico medio
print(f"Solucion propia={SOlUCION},Solucion con numpy={SOlUCION_NP},Error cuadratico medio ={E_C_M}")
#compare sus resultados con el paquete de numpy:
#https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html

"""PRINCIPAL COMPONENT ANALYSIS (PCA)"""

import numpy as np
import matplotlib.pylab as plt

"""EJERCICIO 1"""

#Ejercicio 1:
# Los arrays `u` y `v` representan dos series en función del tiempo `t`.
# 1) Grafique las dos series de datos en una misma imagen y guarde dicha gráfica sn mostrarla en 'serie.pdf'
# 2) Calcule la covarianza entre `u` y `v` e imprima su valor.
# 3) Calcule la varianza de `u` e imprima su valor.
# 4) Imprima un mensaje donde explique qué puede inferir del valor de covarianza obtenido.
import numpy as np
t = np.array([0.,0.1,0.2,0.3,0.4,0.5,0.6, 0.8, 0.9])
u = np.array([-12.,-45.,-6.,-78.,-34.,-22.,10.,-31.,27.])
v = np.array([3.,11.,1.3,37.,11.,6.,-23.,7.,7.])

# 5) Construya un código para obtener la matriz de covarianza de los datos anteriores. (compare su resultado con el de numpy.cov)
plt.figure(0)
plt.plot(t,u,t,v)
plt.grid()

cov=((u-np.mean(u))*(v-np.mean(v))).sum()/(len(u)-1)
var_U=(np.power((u-np.mean(u)),2)).sum()/(len(u)-1)
var_V=(np.power((v-np.mean(v)),2)).sum()/(len(v)-1)

print(f"La covarianza es = {cov} y varianza de u es = {var_U}")
Coef_Corre=cov/np.sqrt(var_U*var_V)
UV=np.array([u,v])
print(f"Se obtuvo un valor de correlación de {cov}, lo cual indica que las variables u y v son inversamente proporcionales. Además, se registró un coeficiente de correlación del {np.abs(Coef_Corre)*100}%, lo que sugiere la existencia de una fuerte relación lineal entre las variables mencionadas")
#FUNCION DE MATRIZ DE COVARIANZA
def Mat_COV(A):
  N=len(A[0,:])
  N1=len(A[:,0])
  MV=np.zeros((N1,N1))
  for i in range(N1):
    for j in range(i,N1):
      aux=((A[i,:]-np.mean(A[i,:]))*(A[j,:]-np.mean(A[j,:]))).sum()/(N-1)
      if i == j:
        MV[i,i]=aux
      else:
        MV[i,j]=aux
        MV[j,i]=aux
  return MV
print(f"Matriz de covarianza eje1:{Mat_COV(UV)}")

"""EJERCICIO 2:"""

from re import M
# 6) Repita lo anterior para obtener la matriz de covarianza de los datos del archivo: room-temperature.csv
nombre_archivo = 'room-temperature.csv'
datos = np.genfromtxt(nombre_archivo, delimiter=',', skip_header=1,usecols=(1,2,3,4))
# 6a) Grafique las 4 series de datos en una misma imagen y guarde dicha gráfica sin mostrarla en 'serieTemp.pdf'
t=range(0,len(datos[:,0]))
plt.figure(1)
plt.plot(t,datos[:,0],label='Data 1')
plt.plot(t,datos[:,1],label='Data 2')
plt.plot(t,datos[:,2],label='Data 3')
plt.plot(t,datos[:,3],label='Data 4')
plt.legend(loc='best')
plt.grid()
plt.savefig('serieTemp.pdf')
# 7) Calcule los autovalores y los autovectores de la matriz de covarianza de los datos de temperatura.

from numpy import linalg as LA
MATRIZ_COV_AUX=Mat_COV(datos.T)#Esta matriz se usara para la normalizacion de los datos y poder realizar PCA
#NORMALIZACION DE LOS DATOS
for i in range(len(datos[0,:])):
  datos[:,i]=(datos[:,i]-np.mean(datos[:,i]))/np.sqrt(MATRIZ_COV_AUX[i,i])
#Matriz de Covarianza
MATRIZ_COV=Mat_COV(datos.T)

eigenvalues, eigenvectors = LA.eig(MATRIZ_COV)
#(use el paquete: https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html)

# 8) Lea: https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c
#Organice sus autovalores y autovectores e imprima cuales son sus componentes principales (puede usar paquetes de numpy para encontrar autovalores y autovectores. lea cuidadosamente la documentación.)
# 9) Imprima cuantos componentes principales considera que son necesarios para explicar sus datos.
x=range(1,5)
Var_PC_Acumulada=np.array([eigenvalues[0]])
for i in range(1,len(eigenvalues)):
  Var_PC_Acumulada=np.append(Var_PC_Acumulada,[Var_PC_Acumulada[i-1]+eigenvalues[i]])

plt.figure(2)
plt.plot(x,eigenvalues/np.sum(eigenvalues),'-o',label='Varianza normalizada de PC')#Valor del eigenvalor normalizado
plt.plot(x,Var_PC_Acumulada/np.sum(eigenvalues),'-o',label='Total varianza de los PCs')#ponderado del eigenvalor normalizado para obtener una varianza igual a 1
plt.legend(loc='best')
plt.grid()
#De acuerdo con la figura anterior, se considera que con 2 componentes ya es posible representar la base de datos (PC1 PC2)

# 10) Grafique sus datos en el nuevo sistema de referencia (PC1 PC2)
#Para esto se hace un producto punto entre los eigenvectores y el vector conformado por los 4 columnas de la base de datos
B_D_PC1=np.dot(datos,eigenvectors[0])
B_D_PC2=np.dot(datos,eigenvectors[1])

plt.figure(3)
plt.plot(B_D_PC2,B_D_PC1,'bo',markersize=1)
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.grid()
# 11) Comente cuales son las agrupaciones de sus variables originales que aparecen. Mire en su gráfica de los datos originales si el resultado tiene sentido.
#Podemos observar un agrupamiento de los datos, o más bien, un rechazo de los puntos de ubicarse por debajo de la diagonal

"""EJERCICIO 3:"""

# 12) Repita lo anterior para obtener la matriz de covarianza de los datos del archivo: WCBD.dat
nombre_archivo_2= 'WDBC.dat'
Datos_Full = np.genfromtxt(nombre_archivo_2, delimiter=',')
Datos=Datos_Full[:,2:]#sin La columna de benigno o maligno
Ben_O_Mal=Datos_Full[:,1]#Colugna benigno o maligno
MATRIZ_COV_AUX_2=Mat_COV(Datos.T)

# 13) Calcule los autovalores y los autovectores de la matriz de covarianza de los datos.
#(use el paquete: https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html)

#NORMALIZACION DE LOS DATOS
for i in range(len(Datos[0,:])):
  Datos[:,i]=(Datos[:,i]-np.mean(Datos[:,i]))/np.sqrt(MATRIZ_COV_AUX_2[i,i])
#Matriz de Covarianza
MATRIZ_COV_2=Mat_COV(Datos.T)
eigenvalues_2, eigenvectors_2 = LA.eig(MATRIZ_COV_2)

# 14) Lea: https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c
#Organice sus autovalores y autovectores e imprima cuales son sus componentes principales (puede usar paquetes de numpy para encontrar autovalores y autovectores. lea cuidadosamente la documentación.)
#ya estan organizados
# 15) Imprima cuantos componentes principales considera que son necesarios para explicar sus datos.
x=range(1,31)
Var_PC_Acumulada_2=np.array([eigenvalues_2[0]])
for i in range(1,len(eigenvalues_2)):
  Var_PC_Acumulada_2=np.append(Var_PC_Acumulada_2,[Var_PC_Acumulada_2[i-1]+eigenvalues_2[i]])

plt.figure(4)
plt.plot(x,eigenvalues_2/np.sum(eigenvalues_2),'-o',label='Varianza normalizada de PC')#Valor del eigenvalor normalizado
plt.plot(x,Var_PC_Acumulada_2/np.sum(eigenvalues_2),'-o',label='Total varianza de los PCs')#ponderado del eigenvalor normalizado para obtener una varianza igual a 1
plt.legend(loc='best')
plt.grid()
#por facilidad de reprecentacion grafica se escogen los dos primeros teniendo una varianza acumulada mayor al 60%
# 16) Grafique sus datos en el nuevo sistema de referencia (PC1 PC2)
B_D2_PC1=np.dot(Datos,eigenvectors_2[:,0])
B_D2_PC2=np.dot(Datos,eigenvectors_2[:,1])

Benigno_PC1=B_D2_PC1[Ben_O_Mal == 0]
maligno_PC1=B_D2_PC1[Ben_O_Mal == 1]

Benigno_PC2=B_D2_PC2[Ben_O_Mal == 0]
maligno_PC2=B_D2_PC2[Ben_O_Mal == 1]

plt.figure(5)
plt.plot(Benigno_PC1,Benigno_PC2,'bo',markersize=1,label='Benigno')
plt.plot(maligno_PC1,maligno_PC2,'ro',markersize=1,label='maligno')

plt.xlabel('PC1')
plt.ylabel('PC2')
plt.grid()
plt.show()

# 17) Puede ver agrupaciones entre los tumores malignos y benignos?
#si,se logran distingir dos nubes de puntos en los que aparecen en los que
#se difencian los tumores benignos de los malignos

"""RECUERDE LOS PASOS:

descargar y limpiar los datos. Ampliarlos (si aplica)

restarles el promedio y normalizar (si aplica)

Calcular la matriz de covarianza de los datos

Encontrar autovalores y autovectores (usar paquete de numpy), y organizarlos (de mayor a menor autovalor)

Mirar los autovalores y decidir cuántos componentes principales (autovectores) mantener.


"""

